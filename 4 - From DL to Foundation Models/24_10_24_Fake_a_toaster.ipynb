{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to fake a toaster\n",
    "\n",
    "- Minor AAI HvA\n",
    "- Michiel Bontenbal & Maarten Post\n",
    "- Computer Vision les 4\n",
    "- Woensdag 24 okteober 2024\n",
    "\n",
    "Code werkt op in Keras 2 en Keras 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code inspired by the blogpost: [*Machine Learning is Fun Part 8: How to Intentionally Trick Neural Networks*](https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196) by Adam Geitgey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install and imports\n",
    "First set up our environmen. We will download the InceptionV3 Deep Neural Network from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install PIL.\n",
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 13:08:22.073773: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import keras.utils as image\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "\n",
    "# Load pre-trained image recognition model\n",
    "model = inception_v3.InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.0\n",
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "#check available devices\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Change the classification by adding a pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example image from the blogpost, found using Google Image Search: \n",
    "\n",
    "![A persian cat](cat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image file and convert it to a numpy array\n",
    "img = image.load_img(\"cat.png\", target_size=(299, 299))\n",
    "input_image = image.img_to_array(img)\n",
    "\n",
    "# Scale the image so all pixel intensities are between [-1, 1] as the model expects\n",
    "input_image /= 255.\n",
    "input_image -= 0.5\n",
    "input_image *= 2.\n",
    "\n",
    "# Add a 4th dimension for batch size (as Keras expects)\n",
    "input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "# Run the image through the neural network\n",
    "predictions = model.predict(input_image)\n",
    "\n",
    "# Convert the predictions into text and print them\n",
    "predicted_classes = inception_v3.decode_predictions(predictions, top=1)\n",
    "imagenet_id, name, confidence = predicted_classes[0][0]\n",
    "print(\"This is a {} with {:.4}% confidence!\".format(name, confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to create an image that will be recognised as a toaster, by making small changes to our cat image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Load pre-trained image recognition model\n",
    "model = inception_v3.InceptionV3()\n",
    "\n",
    "# Grab a reference to the first and last layer of the neural net\n",
    "model_input_layer = model.layers[0].input\n",
    "model_output_layer = model.layers[-1].output\n",
    "\n",
    "# Choose an ImageNet object to fake\n",
    "# The list of classes is available here: https://gist.github.com/ageitgey/4e1342c10a71981d0b491e1b8227328b\n",
    "# Class #859 is \"toaster\"\n",
    "object_type_to_fake = 859\n",
    "\n",
    "# Load the image to hack\n",
    "img = image.load_img(\"cat.png\", target_size=(299, 299))\n",
    "original_image = image.img_to_array(img)\n",
    "\n",
    "# Scale the image so all pixel intensities are between [-1, 1] as the model expects\n",
    "original_image /= 255.\n",
    "original_image -= 0.5\n",
    "original_image *= 2.\n",
    "\n",
    "# Add a 4th dimension for batch size (as Keras expects)\n",
    "original_image = np.expand_dims(original_image, axis=0)\n",
    "\n",
    "# Pre-calculate the maximum change we will allow to the image\n",
    "# We'll make sure our hacked image never goes past this so it doesn't look funny.\n",
    "# A larger number produces an image faster but risks more distortion.\n",
    "max_change_above = original_image + 0.1\n",
    "max_change_below = original_image - 0.1\n",
    "\n",
    "# Create a copy of the input image to hack on\n",
    "hacked_image = np.copy(original_image)\n",
    "\n",
    "# How much to update the hacked image in each iteration\n",
    "learning_rate = 2\n",
    "\n",
    "# Define the cost function.\n",
    "# Our 'cost' will be the likelihood our image is the target class according to the pre-trained model\n",
    "cost_function = model_output_layer[0, object_type_to_fake]\n",
    "\n",
    "# We'll ask Keras to calculate the gradient based on the input image and the currently predicted class\n",
    "# In this case, referring to \"model_input_layer\" will give us back image we are hacking.\n",
    "gradient_function = K.gradients(cost_function, model_input_layer)[0]\n",
    "\n",
    "# Create a Keras function that we can call to calculate the current cost and gradient\n",
    "grab_cost_and_gradients_from_model = K.function([model_input_layer, K.learning_phase()], [cost_function, gradient_function])\n",
    "\n",
    "cost = 0.0\n",
    "print(\"Hacking image...\")\n",
    "# In a loop, keep adjusting the hacked image slightly so that it tricks the model more and more\n",
    "# until it gets to at least 80% confidence\n",
    "while cost < 0.80:\n",
    "    # Check how close the image is to our target class and grab the gradients we\n",
    "    # can use to push it one more step in that direction.\n",
    "    # Note: It's really important to pass in '0' for the Keras learning mode here!\n",
    "    # Keras layers behave differently in prediction vs. train modes!\n",
    "    cost, gradients = grab_cost_and_gradients_from_model([hacked_image, 0])\n",
    "\n",
    "    step = gradients * learning_rate\n",
    "    \n",
    "    # print(\"Max steps: {:4}. Min steps: {:4}\".format(step.max(), step.min()))\n",
    "    \n",
    "    # Move the hacked image one step further towards fooling the model\n",
    "    hacked_image += gradients * learning_rate\n",
    "\n",
    "    # Ensure that the image doesn't ever change too much to either look funny or to become an invalid image\n",
    "    hacked_image = np.clip(hacked_image, max_change_below, max_change_above)\n",
    "\n",
    "    print(\"Model's predicted likelihood that the image is a toaster: {:.4}%\".format(cost * 100))\n",
    "\n",
    "# De-scale the image's pixels from [-1, 1] back to the [0, 255] range\n",
    "img = hacked_image[0]\n",
    "img /= 2.\n",
    "img += 0.5\n",
    "img *= 255.\n",
    "\n",
    "# Save the hacked image!\n",
    "# Resize to original size\n",
    "width = 235\n",
    "height = 177\n",
    "n_img = zoom(img, (height/299, width/299, 1))\n",
    "im = Image.fromarray(n_img.astype(np.uint8))\n",
    "im.save(\"hacked-image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ![The toaster](hacked-image.png) |\n",
    "|:--:|\n",
    "| *Toaster* |\n",
    "\n",
    "| ![The cat](cat.png) |\n",
    "|:--:|\n",
    "| *Cat* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflectievragen\n",
    "\n",
    "Beantwoord de volgende vragen.\n",
    "1. Als je goed kijkt naar de foto's, zie je dan verschil?\n",
    "2. Probeer in je eigen woorden te beschrijven wat er gebeurt in dit proces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
